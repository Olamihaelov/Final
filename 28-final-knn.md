# KNN – תשובות

---

האם האלגוריתם KNN פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?

**תשובה:**  
גם וגם.

---

מה המשמעות של השם KNN?

**תשובה:**  
K-Nearest Neighbors = K השכנים שהכי קרובים לדוגמה.

---

מהו הרעיון המרכזי שעליו מבוסס האלגוריתם KNN?

**תשובה:**  
מסתכלים על הדוגמאות הקרובות ביותר לדוגמה החדשה, ולפיהן קובעים את התשובה.

---

מהו התפקיד של הפרמטר K באלגוריתם?

**תשובה:**  
K קובע כמה שכנים “נחשב” לפני שמחליטים מה התחזית.

---

האם K נחשב Hyperparameter? הסבר/י

**תשובה:**  
כן. בוחרים אותו מראש.

---

כיצד בחירת ערך קטן של K משפיעה על המודל?

**תשובה:**  
המודל נהיה מאוד מושפע מנקודות בודדות, ולכן יכול לטעות בגלל רעש (יותר Overfitting).

---

כיצד בחירת ערך גדול של K משפיעה על המודל?

**תשובה:**  
ההחלטה נהיית יותר כללית ופחות רגישה לפרטים, ולכן יכול להיות Underfitting.

---

בכדי למדוד את ה- K האידיאלי נשתמש בגרף ה ELBOW  
הסבר מה זה גרף ELBOW? מה בד"כ יש בציר ה- X וציר ה- Y?  
כיצד נבחר את ה- Sweet Spot?  
תן דוגמא לעוד מודל ששם נשתמש בגרף זה והסבר כיצד?

**תשובה:**  
גרף Elbow מראה איך התוצאה משתנה כשמשנים את K.  
בדרך כלל:  
- ציר X: ערכי K  
- ציר Y: שגיאה או מדד ביצוע  
ה־Sweet Spot הוא המקום שבו כבר אין שיפור גדול (נקודת “המרפק”).  
דוגמה נוספת: ב־K-Means משתמשים בגרף Elbow כדי לבחור כמה תוצאות K כדאי לקחת.

---

מה ההבדל בין KNN לקלסיפיקציה לבין KNN לרגרסיה?

**תשובה:**  
בקלסיפיקציה מחזירים תווית/מחלקה, וברגרסיה מחזירים מספר.

---

כיצד מתקבלת התחזית ב־KNN לקלסיפיקציה?

**תשובה:**  
הולכים לפי המחלקה שמופיעה הכי הרבה בין K השכנים.

---

כיצד מתקבלת התחזית ב־KNN לרגרסיה?

**תשובה:**  
לוקחים ממוצע של הערכים של K השכנים.

---

איזו מדידת מרחק נפוצה משמשת ב־KNN?

**תשובה:**  
מרחק אוקלידי (Euclidean).

---

כיצד מספר הפיצ'רים משפיע על ביצועי KNN?

**תשובה:**  
כשיש הרבה פיצ'רים, “קרבה” נהיית פחות ברורה, ולכן KNN יכול לעבוד פחות טוב.

---

האם קיים שלב אימון (Training) מובהק באלגוריתם KNN?

**תשובה:**  
לא. כמעט אין אימון — פשוט שומרים את הנתונים.

---

כיצד Python פותר את חישוב KNN – האם באמצעות נוסחה סגורה או באמצעות חישוב ישיר בזמן החיזוי?

**תשובה:**  
חישוב ישיר בזמן חיזוי: מחשבים מרחקים ואז בוחרים את השכנים הקרובים.

---

מהם היתרונות המרכזיים של KNN?

**תשובה:**  
קל להבנה, אין תהליך אימון מסובך, ויכול לעבוד טוב כשדוגמאות דומות נמצאות קרוב.

---

מהם החסרונות המרכזיים של KNN?

**תשובה:**  
חיזוי איטי על הרבה נתונים, צריך נרמול/סקייל לפיצ'רים, ופחות טוב כשיש הרבה מימדים או רעש.

---
