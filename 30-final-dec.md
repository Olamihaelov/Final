# Decision Tree

האם מודל Decision Tree פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?

**תשובה**  
Decision Tree מתאים גם לקלסיפיקציה וגם לרגרסיה.

---

מהו הרעיון המרכזי שעליו מבוסס מודל Decision Tree?

**תשובה**  
המודל מחלק את הנתונים שוב ושוב לפי תנאים על הפיצ'רים (שאלות כן/לא), עד שמגיעים לקבוצות קטנות והומוגניות יותר, ומהן מפיקים את התחזית.

---

מהו Gini Impurity?

**תשובה**  
Gini Impurity הוא מדד לכמה הצומת "מעורבב" מבחינת מחלקות.  
ככל שהערכים בצומת מעורבים יותר בין מחלקות שונות – ה־Gini גבוה יותר.

---

כיצד Gini Impurity מודד את איכות הפיצול?

**תשובה**  
לכל פיצול מחשבים את ה־Gini בכל צומת בן, ושוקלים אותם לפי גודל הצומת.  
פיצול טוב הוא כזה שמקטין כמה שיותר את ערך ה־Gini הכולל (העלים נקיים יותר).

---

מה הערך של Gini Impurity כאשר הצומת "טהור" לחלוטין?

**תשובה**  
כאשר כל הדוגמאות בצומת שייכות לאותה מחלקה, Gini Impurity שווה 0.

---

מהי מטרת הפיצול בכל צומת בעץ?

**תשובה**  
המטרה היא למצוא פיצול שמפריד את הנתונים כך שכל צד יהיה כמה שיותר "נקי" (הומוגני) מבחינת המחלקה או הערך.

---

הסבר את תצורת הפיצול בעץ כאשר מדובר בבעיית רגרסיה

**תשובה**  
ברגרסיה, עץ ההחלטות מחפש פיצול שמפחית כמה שיותר את הפיזור של ערכי ה-Y בכל צד.  
הוא בודק פיצ'רים וערכי סף שונים, ובוחר את הפיצול שהופך את הקבוצות לדומות יותר בתוכן (פחות מפוזרות). 
בסוף, התחזית בעלה היא פשוט הממוצע של כל ערכי ה-Y בדוגמאות האימון שנמצאות שם.  

---

כאשר הגענו לתחתית העץ כיצד מחושב ערך התחזית מ- 2 העלים?

**תשובה**  
ב-Decision Tree משתמשים בעלה אחד בלבד – זה שהנקודה החדשה מגיעה אליו אחרי מעבר בכל הפיצולים.  
בקלסיפיקציה: התחזית היא המחלקה הנפוצה ביותר בעלה זה (ה-Majority Class).  
ברגרסיה: התחזית היא הממוצע של ערכי ה-Y בכל הדוגמאות בעלה זה.  
אין שילוב או ממוצע בין כמה עלים – כל נקודה חדשה מקבלת תחזית מעלה אחד יחיד.  

---

אילו Hyperparameters נפוצים קיימים ב־Decision Tree?

**תשובה**  
- max_depth – עומק מקסימלי של העץ.  
- min_samples_split – מינימום דוגמאות הדרושות לפיצול צומת.  
- min_samples_leaf – מינימום דוגמאות בעלה.  
- max_features – מספר הפיצ'רים שבוחנים בכל פיצול.  
- criterion – מדד לבחירת פיצול (למשל Gini / Entropy בקלסיפיקציה, MSE ברגרסיה).

---

כיצד עומק העץ (Tree Depth) משפיע על Overfitting ו־Underfitting?

מה קורה כאשר העץ עמוק מאוד?

מה קורה כאשר העץ רדוד מאוד?

**תשובה**  
* עץ עמוק מאוד:  
  - לומד פרטים קטנים ורעש ספציפי לדאטה.  
  - נוטה ל־Overfitting – מצטיין באימון, חלש על נתונים חדשים.

- עץ רדוד מאוד:  
  - פשוט מדי, לא "מבין" דפוסים מורכבים.  
  - נוטה ל־Underfitting – ביצועים חלשים גם על האימון וגם על הטסט.

---

אילו מדדי ביצוע מתאימים להערכת מודל Decision Tree בקלסיפיקציה וברגרסיה?

**תשובה**  
* לקלסיפיקציה:  
  - Accuracy  
  - Precision, Recall, F1 Score  
  - Confusion Matrix  

- לרגרסיה:  
  - MSE (Mean Squared Error)  
  - RMSE (Root MSE)  
  - MAE (Mean Absolute Error)  
  - R² 

---
