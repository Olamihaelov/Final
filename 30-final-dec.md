# Decision Tree – תשובות

---

האם מודל Decision Tree פותר בעיית קלסיפיקציה, רגרסיה או גם וגם?

**תשובה:**  
גם וגם (קלסיפיקציה וגם רגרסיה).

---

מהו הרעיון המרכזי שעליו מבוסס מודל Decision Tree?

**תשובה:**  
שואלים שאלות על הפיצ'רים ומפצלים את הנתונים שלב אחרי שלב, עד שמגיעים לעלה שנותן תשובה.

---

מהו Gini Impurity?

**תשובה:**  
מדד שמראה כמה הצומת “מעורבב” בין מחלקות.

---

כיצד Gini Impurity מודד את איכות הפיצול?

**תשובה:**  
פיצול טוב הוא כזה שמוריד את ערך ה־Gini ומייצר צמתים יותר “נקיים”.

---

מה הערך של Gini Impurity כאשר הצומת "טהור" לחלוטין?

**תשובה:**  
0.

---

מהי מטרת הפיצול בכל צומת בעץ?

**תשובה:**  
להגיע לקבוצות יותר אחידות, כדי שהניבוי יהיה יותר מדויק.

---

הסבר את תצורת הפיצול בעץ כאשר מדובר בבעיית רגרסיה

**תשובה:**  
מפצלים כך שבכל צד הערכים יהיו כמה שיותר קרובים, כלומר הטעות (למשל MSE) תרד.

---

כאשר הגענו לתחתית העץ כיצד ניתן תחזית בקלאסיפיקציה וברגרסיה?

**תשובה:**  
בקלאסיפיקציה: מחזירים את המחלקה הכי נפוצה בעלה.  
ברגרסיה: מחזירים את הממוצע של ערכי ה־Y בעלה.

---

אילו Hyperparameters נפוצים קיימים ב־Decision Tree?

**תשובה:**  
max_depth, min_samples_split, min_samples_leaf, max_features, criterion (gini בקלסיפיקציה, squared_error ברגרסיה), max_leaf_nodes.

---

כיצד עומק העץ (Tree Depth) משפיע על Overfitting ו־Underfitting?

מה קורה כאשר העץ עמוק מאוד?

מה קורה כאשר העץ רדוד מאוד?

**תשובה:**  
עץ עמוק מאוד נוטה ל־Overfitting.  
עץ רדוד מאוד נוטה ל־Underfitting.

---

אילו מדדי ביצוע מתאימים להערכת מודל Decision Tree בקלסיפיקציה וברגרסיה?

**תשובה:**  
בקלסיפיקציה: Accuracy, Precision, Recall, F1, Confusion Matrix.  
ברגרסיה: MSE, MAE, R².

---
